{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ce900f",
   "metadata": {},
   "source": [
    "### Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3717b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfb7f9",
   "metadata": {},
   "source": [
    "### Using CUDA if it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6821621",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440c836",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a0732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "sequence_length = 28\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec0c7c",
   "metadata": {},
   "source": [
    "### Creating a Recurrent Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad767f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Forward Propagation\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out.reshape(x.shape[0],-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675eaa74",
   "metadata": {},
   "source": [
    "### Checking the model on random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d877170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = RNN(28,256,2,10)\n",
    "x = torch.randn(64,28,28)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4ac9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2df001b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1171e-01,  9.5957e-02, -5.5159e-02, -1.4504e-02, -1.2041e-01,\n",
       "          5.6838e-02,  3.1331e-02, -8.4525e-02,  2.0487e-02, -1.6939e-01],\n",
       "        [ 1.4707e-01, -6.2357e-02,  7.9535e-02,  3.3588e-02, -1.2882e-01,\n",
       "          1.2851e-01, -1.6320e-01,  3.9704e-02,  4.7919e-02, -7.5878e-02],\n",
       "        [-4.7012e-02, -4.9080e-02, -1.8756e-01, -1.0445e-01, -2.0444e-02,\n",
       "         -1.1676e-01, -8.9245e-03,  1.6870e-02, -3.0442e-02, -1.0440e-01],\n",
       "        [-4.6200e-02, -1.0749e-01, -2.0220e-01, -4.4510e-03, -1.8582e-01,\n",
       "          3.3873e-02,  2.1148e-02,  2.8845e-02, -5.8076e-03, -5.7431e-02],\n",
       "        [-2.7275e-01, -1.1894e-01,  7.0030e-02, -1.1961e-02, -1.0902e-02,\n",
       "         -1.0820e-01, -2.0195e-02, -5.1798e-03,  7.3270e-03, -4.2017e-03],\n",
       "        [ 7.2873e-02, -1.8564e-01,  6.6162e-04,  1.0725e-01, -1.0456e-01,\n",
       "          7.5477e-02, -2.3331e-02, -2.8112e-03,  8.2449e-02, -4.4629e-02],\n",
       "        [-2.9909e-02,  1.7234e-02,  8.8662e-02,  3.8701e-02,  2.5587e-02,\n",
       "          8.2994e-02,  7.4919e-02,  5.9983e-02,  8.7855e-02,  4.6184e-02],\n",
       "        [ 6.9326e-02, -5.0166e-02, -2.8067e-02, -2.3800e-02, -1.4611e-01,\n",
       "          1.0255e-01,  1.1893e-02,  9.7152e-02,  2.0693e-02, -1.1577e-01],\n",
       "        [-2.8920e-03, -3.8863e-02, -1.0198e-01,  1.1753e-01,  4.5782e-02,\n",
       "          6.1337e-02,  3.1283e-02, -5.4077e-02,  3.1823e-02, -5.9489e-02],\n",
       "        [-8.1461e-02,  6.8237e-02,  1.4980e-01,  1.5082e-01, -4.1929e-02,\n",
       "         -7.9002e-02,  7.0233e-04,  1.0664e-01,  1.9329e-02, -6.0919e-03],\n",
       "        [-2.0561e-02, -1.9495e-01, -1.1510e-02, -7.9199e-02, -1.0970e-01,\n",
       "         -3.8134e-02,  9.4148e-03,  2.8982e-03,  4.3888e-03, -3.2757e-02],\n",
       "        [ 5.2491e-02,  9.7825e-02,  2.3650e-01, -9.9064e-02,  4.1529e-02,\n",
       "         -1.6788e-01,  3.7085e-02, -9.1375e-02, -9.6291e-02, -9.8720e-02],\n",
       "        [-2.1914e-01,  1.7511e-03,  7.6575e-02, -1.5348e-01, -1.7908e-02,\n",
       "          1.0494e-01,  9.9135e-02, -1.9423e-01, -9.3141e-02, -9.6137e-02],\n",
       "        [-8.8306e-02, -1.1468e-02, -1.7932e-02, -1.4443e-01, -7.4187e-02,\n",
       "         -8.9380e-02, -5.3486e-02, -5.1812e-02, -2.9216e-02, -2.5440e-02],\n",
       "        [ 3.6382e-02,  4.1751e-02,  1.6179e-02, -1.2937e-01, -6.9345e-02,\n",
       "         -7.8209e-03, -1.9235e-02, -8.4045e-02,  1.3775e-01,  4.4611e-03],\n",
       "        [-3.3396e-02, -1.2857e-01,  7.9922e-02, -4.5109e-03,  4.3167e-02,\n",
       "         -7.0284e-02,  2.2243e-02, -5.4789e-02,  7.2520e-02,  6.9884e-03],\n",
       "        [-1.9139e-01,  2.5463e-02, -5.4939e-02,  3.2610e-02,  3.2733e-02,\n",
       "         -1.4771e-01,  2.2840e-02,  2.4109e-02, -2.9719e-01,  1.2810e-01],\n",
       "        [ 3.5192e-02, -5.9071e-02,  1.6896e-01, -1.0228e-01,  4.5020e-02,\n",
       "          3.4029e-02, -9.1853e-02, -4.3964e-02, -1.4431e-01, -9.9172e-03],\n",
       "        [-7.4994e-02, -4.9729e-03, -1.5468e-02, -3.9051e-02,  3.0193e-02,\n",
       "         -2.1792e-02,  1.4716e-01, -1.1457e-01,  1.7959e-01,  4.8050e-02],\n",
       "        [-5.0802e-02, -9.4231e-02,  1.1553e-01,  1.0551e-01,  1.9831e-02,\n",
       "         -9.4766e-02, -1.0570e-01,  7.0291e-02,  1.8120e-01, -2.9972e-02],\n",
       "        [-5.3968e-02, -1.3350e-01, -1.4231e-01,  1.2698e-02, -4.3370e-02,\n",
       "         -5.6098e-02,  2.2774e-02, -7.4606e-02,  5.2745e-02, -1.1605e-01],\n",
       "        [-1.5410e-02, -1.2338e-01,  9.4959e-02,  5.4982e-02, -5.9224e-02,\n",
       "         -1.2054e-01,  5.1780e-02,  2.1777e-02, -2.8230e-02, -2.1038e-02],\n",
       "        [-1.4599e-01, -1.6483e-01,  5.6638e-02,  1.5021e-02, -6.0307e-02,\n",
       "         -1.1279e-02, -1.4885e-01, -3.2647e-02,  4.5125e-02, -7.7630e-02],\n",
       "        [-7.5958e-02,  7.5782e-03,  9.6132e-03,  3.6081e-02,  8.0155e-03,\n",
       "          2.0963e-01, -1.6316e-01, -6.5688e-02, -8.2114e-02,  2.8064e-02],\n",
       "        [ 1.6510e-02,  3.1878e-03, -6.1845e-02,  3.8634e-02,  8.9435e-02,\n",
       "         -1.4963e-02,  1.1985e-02,  1.7291e-01, -1.7348e-02, -1.3530e-01],\n",
       "        [-1.5346e-01, -1.7865e-02, -2.6702e-02,  1.6136e-02, -5.1586e-02,\n",
       "          1.2391e-01, -6.5060e-02, -2.7926e-02, -5.6693e-02, -6.3182e-02],\n",
       "        [-4.2605e-02, -2.3929e-02,  1.4367e-01, -3.8989e-03, -1.5880e-01,\n",
       "          2.6229e-02,  1.9216e-01,  3.5005e-02,  3.5586e-02,  8.4196e-02],\n",
       "        [-9.7925e-02,  2.1619e-02,  7.1210e-02, -1.5383e-02,  4.5789e-02,\n",
       "         -2.1614e-02, -4.9853e-02,  2.2180e-01,  1.1992e-01, -7.5252e-02],\n",
       "        [-5.2139e-02,  2.0382e-02, -1.1018e-01,  9.9028e-02, -4.5762e-02,\n",
       "          1.6288e-02,  8.5630e-02,  4.0237e-02,  1.2773e-01,  1.2610e-02],\n",
       "        [-8.9062e-02, -1.4006e-02,  7.6009e-02,  9.3494e-02, -8.9770e-02,\n",
       "         -1.1158e-03, -7.7973e-02,  1.5093e-01,  7.7175e-02, -6.8065e-02],\n",
       "        [ 9.0927e-03, -1.0602e-01,  3.2685e-02, -1.3967e-01,  1.1482e-01,\n",
       "         -2.4943e-02,  8.7222e-02, -5.9581e-02, -4.1580e-02, -6.4011e-02],\n",
       "        [ 4.2783e-02, -1.0537e-01,  3.9923e-02, -1.0205e-01,  4.2926e-02,\n",
       "         -7.9731e-02,  1.7778e-02, -2.3239e-02,  8.3605e-02,  8.1864e-02],\n",
       "        [-3.1593e-02,  4.5952e-02, -1.6196e-01,  7.0571e-02,  6.6031e-02,\n",
       "         -6.8049e-02,  1.1011e-01, -1.9028e-01, -4.4845e-02,  5.6836e-02],\n",
       "        [-1.9563e-02, -1.1362e-01, -1.5981e-02, -2.6291e-02, -7.6662e-03,\n",
       "          6.7330e-03,  3.7223e-02,  4.9051e-02,  8.8756e-02,  1.0612e-01],\n",
       "        [-1.2612e-01, -1.6718e-01,  1.4154e-01, -8.2053e-02,  9.9606e-03,\n",
       "          2.0003e-02, -8.0392e-02,  9.2764e-02,  5.6603e-03,  4.8678e-02],\n",
       "        [ 1.5780e-02,  3.8883e-02,  1.2699e-02,  4.4874e-02, -3.9005e-02,\n",
       "          1.1043e-01,  1.5008e-01, -8.3676e-02, -7.3802e-02, -1.4507e-02],\n",
       "        [-1.7228e-01,  4.1378e-02,  1.0416e-01, -3.9209e-02, -9.9574e-02,\n",
       "          2.4211e-02,  4.2354e-02, -1.8114e-01,  9.7531e-02,  7.0079e-02],\n",
       "        [-1.7727e-02, -3.1566e-02,  1.3344e-01, -5.6805e-02, -3.8359e-02,\n",
       "         -1.1223e-01,  5.4251e-02, -8.8060e-03,  4.4140e-02,  1.3673e-01],\n",
       "        [ 1.5950e-01,  5.7593e-02,  6.5871e-02,  8.6149e-02,  1.6449e-02,\n",
       "          6.9427e-02,  4.6311e-03, -2.6574e-02, -8.2296e-02, -6.3158e-02],\n",
       "        [-1.0685e-01, -7.2362e-02,  8.4779e-02, -6.0099e-02, -1.0523e-01,\n",
       "          1.0665e-01, -1.7837e-01, -7.5388e-02, -3.0858e-02, -4.6691e-02],\n",
       "        [-1.2570e-01, -4.6249e-02,  6.8442e-02, -1.2360e-01, -1.4646e-02,\n",
       "          7.8423e-02,  1.8584e-02,  2.1894e-02,  5.5231e-02, -5.2606e-02],\n",
       "        [ 6.0121e-02,  7.2247e-02,  1.8874e-01,  1.0468e-02, -6.2038e-02,\n",
       "          2.0493e-01, -1.1700e-01,  9.9482e-02, -4.0567e-02, -1.1038e-01],\n",
       "        [-1.0401e-01,  1.6157e-01, -9.0667e-03,  9.4013e-02,  5.5701e-02,\n",
       "         -1.2603e-01, -3.8827e-02,  5.8918e-02, -1.9074e-01,  1.0286e-01],\n",
       "        [-1.2456e-01, -2.0463e-01, -7.4712e-03, -2.1566e-02, -1.3032e-02,\n",
       "         -2.7991e-02, -7.9419e-02,  1.6384e-01,  5.1312e-02, -8.9810e-02],\n",
       "        [-5.0971e-02, -5.4825e-02, -2.8314e-02,  1.2083e-01, -2.4291e-01,\n",
       "         -3.3764e-02,  1.3950e-02,  4.1135e-02, -9.1870e-03,  5.6389e-02],\n",
       "        [-3.5714e-02, -3.6086e-02, -1.2173e-02, -8.3704e-05, -1.7165e-01,\n",
       "          1.2742e-01, -6.5266e-04,  3.4671e-02, -4.0922e-03, -6.4451e-02],\n",
       "        [-3.2938e-02, -1.4472e-01,  6.4943e-02,  8.8221e-03,  4.3813e-02,\n",
       "          1.5165e-03, -3.6360e-02,  4.0993e-03,  1.5174e-01,  6.7294e-02],\n",
       "        [-1.0087e-01, -4.6156e-02,  1.4015e-01,  8.5193e-02, -1.2611e-01,\n",
       "          1.3112e-01,  2.2269e-03,  1.1562e-01, -1.1854e-01,  7.0485e-02],\n",
       "        [ 5.7861e-02, -1.9770e-01,  7.7098e-02,  1.6349e-02,  2.6272e-02,\n",
       "         -6.8420e-02,  7.4458e-02,  8.1700e-02,  1.0614e-01,  1.1436e-01],\n",
       "        [ 2.3953e-02,  6.8376e-02, -1.9713e-03, -1.4432e-01, -4.8902e-02,\n",
       "         -8.8133e-03, -7.8305e-02, -1.2159e-01,  6.5434e-02, -1.5722e-01],\n",
       "        [-1.4538e-01,  8.9053e-02, -3.4103e-02,  2.7020e-03, -2.2133e-02,\n",
       "         -1.2802e-02, -4.7456e-02,  8.1383e-02,  6.3146e-02,  4.9460e-02],\n",
       "        [-6.3142e-02, -7.4762e-02,  1.4100e-01, -1.3122e-01, -1.5803e-01,\n",
       "          1.0170e-01, -1.0473e-01,  1.8976e-02, -4.4668e-02,  2.8045e-02],\n",
       "        [ 5.8270e-02, -4.1818e-02, -6.4240e-02,  1.2683e-01,  7.8057e-02,\n",
       "         -1.6431e-02, -5.3419e-02,  6.2239e-02,  1.9848e-02, -8.3411e-02],\n",
       "        [-1.3736e-01, -6.4026e-02,  1.1736e-01,  6.6887e-02,  6.5292e-02,\n",
       "          1.1553e-01,  5.2537e-02,  8.6732e-02,  1.4739e-01,  8.2619e-02],\n",
       "        [-1.1295e-01,  1.3267e-01,  3.5435e-03,  4.5289e-02, -1.4855e-01,\n",
       "          3.0388e-03, -2.3649e-02, -1.6525e-01,  3.8284e-02, -5.1893e-02],\n",
       "        [-6.0335e-02, -1.0264e-01,  1.6549e-02, -9.4584e-02,  1.1903e-01,\n",
       "         -3.5811e-03, -9.5782e-02, -1.5038e-02, -2.1803e-02,  6.5740e-02],\n",
       "        [ 4.1079e-02, -1.5576e-01, -2.7179e-02,  8.6061e-02, -1.0300e-02,\n",
       "          3.6101e-02, -1.9939e-02,  8.1225e-02,  9.0234e-03,  9.9301e-03],\n",
       "        [-6.2543e-02, -2.9855e-02, -7.5399e-02, -3.0387e-02,  7.1729e-02,\n",
       "          3.4718e-02,  5.7977e-03, -2.5010e-03, -4.6395e-02, -5.6099e-02],\n",
       "        [-4.1377e-02, -1.7668e-02, -6.8082e-02, -4.4208e-02, -1.2264e-01,\n",
       "         -7.9132e-02, -4.2064e-02,  6.3635e-02,  1.0223e-01, -1.9614e-01],\n",
       "        [-8.8515e-02, -8.6922e-02, -2.1401e-01,  3.8449e-02, -1.7500e-01,\n",
       "          1.5586e-01,  3.7382e-03,  3.2598e-02,  1.3119e-01,  4.0172e-02],\n",
       "        [-1.8899e-01, -1.3831e-02, -6.7509e-02, -1.0801e-01,  8.0819e-02,\n",
       "          5.6042e-02, -1.6956e-01,  4.8901e-02,  6.3794e-03, -2.0548e-02],\n",
       "        [ 1.2392e-01,  3.7851e-02, -2.3872e-02,  1.6145e-02, -4.3197e-02,\n",
       "          5.6716e-03, -6.5546e-02,  7.0724e-02, -4.1848e-02, -4.6574e-02],\n",
       "        [-6.1241e-02, -7.3657e-02,  1.4292e-02,  4.2639e-02, -1.4173e-01,\n",
       "          2.9538e-01,  7.9422e-02,  3.8565e-02, -4.9455e-03,  1.2920e-02],\n",
       "        [-3.3799e-02, -4.5722e-02, -3.2086e-02, -1.0231e-01,  2.1000e-02,\n",
       "         -4.9668e-02,  8.1733e-02, -3.5415e-02,  2.0994e-01, -2.5308e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f0d97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3511,  0.0461, -0.6522, -0.5255, -0.4750, -0.0223,  0.4922, -0.0623,\n",
       "         0.0305,  0.2871, -0.4701, -0.0879, -0.4916, -0.5857, -0.0733, -0.0667,\n",
       "        -0.4254, -0.1682,  0.1341,  0.1169, -0.5317, -0.1443, -0.5247, -0.0879,\n",
       "         0.1032, -0.3224,  0.2876,  0.2203,  0.1938,  0.0576, -0.1920, -0.0015,\n",
       "        -0.1472,  0.1048, -0.1371,  0.1618, -0.1125,  0.1031,  0.2876, -0.4844,\n",
       "        -0.1202,  0.3060,  0.0044, -0.3533, -0.1877, -0.1628,  0.1282,  0.1531,\n",
       "         0.2881, -0.4034,  0.0239, -0.2868,  0.0859,  0.5330, -0.2795, -0.1924,\n",
       "         0.0502, -0.1909, -0.4454, -0.1624, -0.3763,  0.0333,  0.2016, -0.0116],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->i\",arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6fef5",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf5dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='data/',train=True, transform=transforms.ToTensor(),download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='data/',train=False, transform=transforms.ToTensor(),download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131db9d9",
   "metadata": {},
   "source": [
    "### Intialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b39a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size,hidden_size,num_layers,num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d57d3",
   "metadata": {},
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f91635",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d12ef",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc77c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get the data to CUDA if possible\n",
    "        data = data.to(device=device).squeeze(1)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,targets)\n",
    "        \n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Descent\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df6464",
   "metadata": {},
   "source": [
    "### Checking the accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b07e065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 57051/60000 with accuracy 95.08\n",
      "Checking accuracy on test data\n",
      "Got 9537/10000 with accuracy 95.37\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "        \n",
    "    else :\n",
    "        print(\"Checking accuracy on test data\")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    #model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device).squeeze(1)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            \n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    print(f'Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "        \n",
    "    #model.train()\n",
    "\n",
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1cf85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
