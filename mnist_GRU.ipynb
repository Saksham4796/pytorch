{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ce900f",
   "metadata": {},
   "source": [
    "### Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3717b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfb7f9",
   "metadata": {},
   "source": [
    "### Using CUDA if it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6821621",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440c836",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a0732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "sequence_length = 28\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec0c7c",
   "metadata": {},
   "source": [
    "### Creating a Recurrent Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad767f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Forward Propagation\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out.reshape(x.shape[0],-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675eaa74",
   "metadata": {},
   "source": [
    "### Checking the model on random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d877170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = GRU(28,256,2,10)\n",
    "x = torch.randn(64,28,28)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4ac9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2df001b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.0806e-02,  2.2499e-02, -2.1765e-03, -3.3433e-02, -4.0606e-02,\n",
       "         -1.3798e-02,  2.5928e-02,  2.1620e-02, -5.2083e-03, -4.1989e-03],\n",
       "        [-7.1626e-02, -2.4000e-02, -1.5007e-02, -4.0232e-02, -6.1066e-02,\n",
       "          3.6336e-03,  3.0044e-02,  6.2538e-02, -3.3396e-02,  9.7090e-03],\n",
       "        [-6.7653e-02, -7.9656e-02,  3.2971e-02, -1.9640e-02, -5.8909e-02,\n",
       "         -1.1736e-02,  3.7345e-02,  1.3181e-02, -1.5013e-02, -2.2844e-02],\n",
       "        [-5.5630e-02,  2.7584e-02, -2.3073e-02, -5.4636e-02, -9.2567e-03,\n",
       "         -7.0438e-02,  4.2742e-02, -2.9316e-02,  3.1388e-02,  2.2908e-02],\n",
       "        [-3.9422e-02,  2.3543e-02,  4.2559e-02,  6.1401e-03, -5.6717e-03,\n",
       "         -6.0426e-02, -2.8755e-02,  7.4967e-02, -1.7872e-02, -1.4772e-04],\n",
       "        [-3.9505e-02, -2.1356e-02, -1.1055e-02, -8.6820e-03, -2.6310e-02,\n",
       "         -3.7904e-02,  3.4431e-02,  2.7484e-02,  4.8360e-02, -2.5630e-02],\n",
       "        [-1.4477e-02, -6.3565e-02, -1.4688e-02, -3.1345e-02, -7.7132e-03,\n",
       "         -4.7893e-02,  2.3722e-02,  1.4904e-02,  3.7259e-02,  3.1933e-03],\n",
       "        [-5.6394e-02, -1.8828e-02, -4.1246e-02, -1.1157e-01, -2.4295e-02,\n",
       "         -7.6622e-02,  8.3586e-03, -1.6209e-02,  1.1878e-02,  1.0627e-02],\n",
       "        [-9.5839e-02, -6.8923e-02,  4.0805e-02, -5.4180e-02, -3.6025e-02,\n",
       "         -8.1869e-03,  2.4113e-02, -3.9041e-03, -3.7939e-02, -2.3232e-03],\n",
       "        [-3.4222e-02,  1.2883e-02,  3.5469e-02, -3.3748e-02, -3.3846e-02,\n",
       "         -6.8933e-02,  5.9627e-02,  1.4900e-02,  1.7561e-02, -3.2216e-03],\n",
       "        [-7.2631e-02, -7.5749e-02,  6.8441e-03, -4.7554e-02, -2.0366e-02,\n",
       "         -2.1601e-02,  3.0699e-03,  2.2495e-02, -1.7153e-03,  3.8704e-02],\n",
       "        [-8.3504e-02, -6.6358e-02, -2.4012e-02, -7.0864e-02, -1.0405e-02,\n",
       "         -1.1569e-03,  1.5716e-02,  4.6852e-02, -1.3601e-02,  3.7332e-02],\n",
       "        [-8.2304e-02, -3.5734e-02, -2.6245e-02, -1.6716e-02, -1.8392e-02,\n",
       "         -1.9110e-02,  6.3032e-02, -2.6077e-02,  1.8021e-02,  9.4017e-03],\n",
       "        [-8.8369e-02, -7.7405e-02,  1.5278e-02, -2.6286e-02, -2.2354e-02,\n",
       "          1.8831e-02,  2.7958e-03,  4.8265e-02, -1.7651e-02, -1.3036e-02],\n",
       "        [-9.0051e-02, -2.7142e-02, -4.1928e-02, -1.6147e-02, -5.7839e-02,\n",
       "          9.3246e-03,  2.3952e-02, -1.2123e-02, -1.7850e-02, -1.0288e-02],\n",
       "        [-4.9203e-02, -7.2739e-02, -5.9793e-02, -3.1493e-02,  3.9963e-04,\n",
       "         -1.1016e-02,  3.0898e-02,  6.9232e-02, -3.8917e-02,  1.3259e-03],\n",
       "        [-4.5910e-02, -3.3554e-02,  1.6498e-02, -6.9438e-03, -1.1241e-02,\n",
       "         -4.2020e-02,  2.3621e-02, -3.4908e-03, -2.1252e-02,  2.0357e-03],\n",
       "        [-3.1569e-02, -2.4111e-02,  5.5630e-02, -5.9229e-02, -7.1723e-02,\n",
       "         -8.7500e-03,  3.3675e-02,  5.4488e-02,  8.7229e-04, -6.3384e-04],\n",
       "        [-7.1053e-02,  2.1385e-02,  1.3503e-02, -4.1486e-02, -2.6573e-02,\n",
       "         -3.4094e-02,  3.6811e-02,  3.5332e-03, -4.3187e-02,  5.7523e-03],\n",
       "        [-9.7155e-02, -2.7928e-03,  1.7514e-02, -4.8738e-02, -2.7628e-02,\n",
       "         -3.9311e-02,  2.3071e-03, -4.7059e-03,  2.4771e-02, -2.7944e-02],\n",
       "        [-7.5244e-02,  1.2395e-02,  7.4478e-03, -1.6866e-02,  3.3399e-03,\n",
       "         -2.5083e-02,  3.6093e-02,  5.2844e-02,  3.8304e-03,  6.5574e-02],\n",
       "        [-5.6641e-02, -6.9145e-02, -2.6827e-02, -6.8912e-02, -1.7251e-02,\n",
       "         -6.3770e-02,  2.4306e-02,  1.0430e-02, -2.5136e-04, -6.1380e-04],\n",
       "        [-3.5885e-02,  5.2558e-03, -2.6623e-02, -5.0407e-02, -4.0545e-02,\n",
       "          7.9478e-03,  2.7417e-02,  5.2238e-02, -3.9010e-02,  1.4938e-02],\n",
       "        [-7.3585e-02, -1.0174e-02, -3.1956e-02, -3.5938e-02, -2.9251e-02,\n",
       "         -3.5501e-02,  1.7033e-02, -8.9334e-03, -5.2719e-02,  6.5200e-02],\n",
       "        [-1.0110e-01, -1.4846e-02, -3.5274e-02,  1.1479e-02, -3.9562e-02,\n",
       "          2.5727e-02,  6.1593e-02, -1.3642e-02,  1.2092e-02, -3.0077e-02],\n",
       "        [-6.1482e-02, -4.6614e-02,  3.2490e-02, -2.7251e-02, -6.2719e-02,\n",
       "         -2.2192e-02, -3.1751e-02,  7.2678e-02, -2.9471e-02,  8.2432e-03],\n",
       "        [-2.8455e-02,  4.0637e-02, -7.1743e-02,  2.5482e-02, -5.1856e-02,\n",
       "         -2.1540e-02,  5.9826e-02,  2.3291e-02,  4.7724e-03, -2.7007e-02],\n",
       "        [-6.8683e-02, -5.1588e-03, -3.1470e-02,  5.2387e-03,  4.1396e-02,\n",
       "         -3.9023e-02,  2.3889e-02, -2.0678e-02,  1.5678e-02,  4.8632e-02],\n",
       "        [-2.9481e-02, -6.4410e-02, -2.5386e-02, -1.3429e-02, -9.3417e-03,\n",
       "         -2.8620e-02,  7.4390e-02,  1.8596e-02, -1.1378e-02,  2.8039e-02],\n",
       "        [-5.1829e-02,  3.8241e-02, -9.3834e-02, -2.3763e-02, -3.2260e-02,\n",
       "         -7.6628e-02,  3.7159e-02, -1.7582e-02,  1.8095e-02,  2.5587e-02],\n",
       "        [-4.7164e-02, -7.1476e-02,  1.0312e-02, -6.2565e-02, -2.4809e-02,\n",
       "         -3.7366e-02,  1.9391e-02, -4.6542e-03, -3.7350e-02,  3.4923e-02],\n",
       "        [-3.3817e-02, -3.2622e-02, -3.3321e-02, -3.5177e-02, -1.9355e-02,\n",
       "         -5.8064e-02,  9.0840e-03,  4.8751e-02, -8.5825e-04,  1.9325e-02],\n",
       "        [-1.1862e-01, -4.7707e-02,  3.7640e-03, -5.2684e-02, -6.1663e-03,\n",
       "          2.2296e-02,  2.3944e-02,  5.1797e-04, -2.7608e-02, -2.9427e-03],\n",
       "        [-2.8890e-02, -7.1033e-02,  3.1962e-02, -1.2238e-02, -5.0052e-02,\n",
       "         -2.1189e-02,  1.6763e-02,  4.0539e-02,  2.4183e-02,  2.6695e-02],\n",
       "        [-3.3293e-02, -2.8964e-02, -1.1694e-02, -9.1577e-02, -8.5427e-02,\n",
       "         -4.5136e-02,  2.6003e-02,  1.1921e-02, -1.2997e-02,  3.2458e-03],\n",
       "        [-5.8644e-02, -4.9470e-02, -6.1712e-02, -4.8779e-02, -2.6106e-02,\n",
       "         -3.3931e-03,  3.3061e-02,  7.2445e-02,  1.4269e-02, -6.1473e-03],\n",
       "        [-7.5557e-02, -3.5306e-02, -1.5962e-02, -1.8622e-02, -4.9722e-02,\n",
       "         -2.0941e-02,  2.4206e-02,  2.3979e-02,  1.1547e-02, -2.4639e-02],\n",
       "        [-7.6584e-02,  1.9431e-02, -4.1862e-02, -6.5611e-02, -3.0631e-02,\n",
       "         -2.0305e-02,  3.3971e-02,  1.7267e-02, -2.7388e-02, -8.7371e-03],\n",
       "        [-8.3915e-03, -9.2950e-03, -1.8322e-02, -4.0937e-02, -2.2104e-02,\n",
       "         -3.3123e-02,  1.2524e-02,  2.4065e-02,  1.6296e-02,  5.6593e-02],\n",
       "        [-8.9295e-02, -5.7227e-02, -2.0081e-02, -1.0475e-02, -1.3724e-02,\n",
       "         -3.2676e-02,  2.3696e-02, -2.6577e-02, -3.0115e-03,  6.3891e-02],\n",
       "        [-5.3655e-02, -3.2413e-02, -1.2794e-03, -6.8991e-03,  2.2453e-04,\n",
       "          1.2460e-02,  3.0426e-02,  5.7257e-02, -3.6877e-03,  2.1553e-02],\n",
       "        [-6.3479e-02, -5.0113e-02, -5.4045e-02, -1.9719e-02, -5.2244e-02,\n",
       "          4.7374e-03,  3.7703e-02,  6.7416e-03, -3.9461e-03,  1.4351e-02],\n",
       "        [-9.7899e-02, -8.8581e-03, -1.7937e-02, -2.4608e-02, -5.0577e-02,\n",
       "         -7.1144e-03,  3.2834e-02,  2.0651e-02, -6.5621e-03, -7.1698e-03],\n",
       "        [-9.5810e-02,  2.0569e-02, -2.3708e-02, -5.5343e-02, -2.2566e-02,\n",
       "         -3.9602e-02, -8.5688e-03,  1.1102e-02, -2.0674e-02,  5.1866e-02],\n",
       "        [-2.0322e-03, -1.4126e-02, -4.6508e-04, -6.4129e-02, -2.8815e-02,\n",
       "         -5.9006e-02,  4.0573e-02,  4.6871e-02, -1.2073e-02,  1.7602e-02],\n",
       "        [-4.6618e-02, -6.6046e-02,  6.3567e-03, -4.9118e-02, -3.2975e-02,\n",
       "         -1.9238e-02,  2.6060e-02,  4.3400e-03, -5.0399e-02,  2.3352e-02],\n",
       "        [-3.7808e-02, -3.2999e-02, -5.3772e-03, -6.4727e-02,  3.1602e-02,\n",
       "         -3.2869e-02,  2.9700e-02, -2.5988e-02,  2.5282e-02, -4.1314e-03],\n",
       "        [-9.6266e-02,  1.5232e-03, -7.0633e-02, -2.5362e-02, -3.6618e-02,\n",
       "          9.3141e-03,  8.8308e-02, -1.6696e-03, -6.7594e-05,  2.7842e-02],\n",
       "        [-4.6164e-02, -4.0444e-02, -3.7662e-02, -6.2023e-02, -1.2044e-01,\n",
       "         -4.3902e-02,  5.1430e-03, -2.6773e-02, -2.5590e-02,  5.5835e-03],\n",
       "        [-2.6694e-02,  5.6549e-03, -6.0643e-02, -8.5526e-02, -4.5331e-03,\n",
       "         -3.9708e-02,  8.0222e-02, -1.5700e-02,  1.9057e-02, -2.3262e-02],\n",
       "        [-9.8144e-02, -5.8270e-03,  1.7905e-03, -4.3300e-02,  2.4286e-03,\n",
       "         -3.9647e-02,  2.8236e-02,  5.2895e-03, -3.5855e-02,  2.9512e-03],\n",
       "        [-8.4836e-02,  4.3875e-03,  2.2291e-02, -3.1029e-02, -2.5311e-02,\n",
       "         -1.7895e-02,  5.7039e-03,  3.3992e-02, -3.1662e-02, -6.3344e-03],\n",
       "        [-8.1155e-02,  9.0794e-03, -2.6618e-02, -3.4182e-02, -1.6896e-02,\n",
       "          3.4728e-02,  2.0178e-02,  5.4604e-02,  2.8233e-03, -3.1082e-02],\n",
       "        [-5.2320e-02, -1.1295e-02, -1.1756e-02, -7.4280e-02, -3.7983e-02,\n",
       "         -4.4247e-02,  2.2505e-02, -2.9563e-02, -1.4760e-02,  2.4598e-02],\n",
       "        [-2.3514e-02, -5.8113e-03, -1.3662e-02, -5.1692e-02, -3.8142e-02,\n",
       "         -6.5145e-02,  3.8397e-02,  2.6361e-03, -4.4209e-02,  1.0491e-02],\n",
       "        [-7.9565e-02, -4.8431e-02,  1.8232e-02, -2.5351e-02, -6.5306e-03,\n",
       "         -1.8809e-02,  2.1403e-02, -2.1401e-02, -5.2547e-02,  4.0244e-02],\n",
       "        [-1.9515e-02, -2.4922e-02, -9.8645e-03,  2.2692e-02,  2.2042e-02,\n",
       "         -1.6196e-02, -2.3587e-02,  6.7888e-02,  1.1555e-02, -4.2044e-02],\n",
       "        [-4.0383e-02, -5.8851e-02, -4.5912e-02, -1.0051e-01, -3.4049e-02,\n",
       "         -6.1870e-02,  4.1065e-02, -5.2359e-03,  2.5089e-02,  7.7647e-03],\n",
       "        [-6.5445e-02, -1.0569e-02,  2.5735e-02, -6.6306e-02, -3.7075e-02,\n",
       "         -1.1143e-02,  3.2839e-02,  4.6536e-02, -7.2729e-04,  9.0930e-03],\n",
       "        [-6.6114e-02,  4.4003e-03, -8.5393e-03, -4.8314e-02, -3.0587e-02,\n",
       "         -5.5587e-02, -2.0082e-02,  2.8557e-02, -3.4333e-02,  4.5503e-02],\n",
       "        [-1.0137e-01, -2.8301e-02, -3.8548e-02,  1.1357e-02, -6.9732e-04,\n",
       "         -9.3024e-03,  1.9145e-02, -1.5002e-02,  1.1947e-02, -1.2178e-02],\n",
       "        [-8.2247e-02, -2.3046e-02, -3.1243e-02, -7.8371e-02, -6.2141e-02,\n",
       "         -3.3938e-02,  5.9445e-02, -2.1867e-02, -2.4932e-02, -1.5015e-02],\n",
       "        [-8.2152e-02,  8.6291e-03,  4.1124e-03, -8.8977e-02, -7.9425e-02,\n",
       "         -3.7891e-02, -8.3038e-03,  7.3459e-02, -5.5112e-02, -3.5657e-02],\n",
       "        [-7.0692e-02,  2.5352e-02, -2.2302e-02, -5.3780e-02, -2.4877e-03,\n",
       "          1.3085e-02,  3.1852e-02,  2.7796e-02, -4.2391e-02,  2.2992e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f0d97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1002, -0.1394, -0.1920, -0.1177, -0.0051, -0.0602, -0.1006, -0.3143,\n",
       "        -0.2424, -0.0335, -0.1685, -0.1700, -0.1341, -0.1599, -0.2401, -0.1613,\n",
       "        -0.1223, -0.0513, -0.1354, -0.2037,  0.0643, -0.2687, -0.0847, -0.1958,\n",
       "        -0.1236, -0.1681, -0.0466, -0.0302, -0.0610, -0.1768, -0.2208, -0.1361,\n",
       "        -0.2052, -0.0433, -0.2679, -0.1345, -0.1810, -0.2004, -0.0227, -0.1655,\n",
       "         0.0240, -0.1800, -0.1672, -0.1827, -0.0756, -0.2043, -0.1173, -0.1036,\n",
       "        -0.3923, -0.1511, -0.1821, -0.1307, -0.0685, -0.2291, -0.1907, -0.1728,\n",
       "        -0.0120, -0.2729, -0.0771, -0.1851, -0.1629, -0.3134, -0.3013, -0.0706],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->i\",arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6fef5",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf5dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='data/',train=True, transform=transforms.ToTensor(),download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='data/',train=False, transform=transforms.ToTensor(),download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131db9d9",
   "metadata": {},
   "source": [
    "### Intialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b39a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(input_size,hidden_size,num_layers,num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d57d3",
   "metadata": {},
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f91635",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d12ef",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc77c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get the data to CUDA if possible\n",
    "        data = data.to(device=device).squeeze(1)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,targets)\n",
    "        \n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Descent\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df6464",
   "metadata": {},
   "source": [
    "### Checking the accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b07e065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 57700/60000 with accuracy 96.17\n",
      "Checking accuracy on test data\n",
      "Got 9637/10000 with accuracy 96.37\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "        \n",
    "    else :\n",
    "        print(\"Checking accuracy on test data\")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    #model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device).squeeze(1)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            \n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    print(f'Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "        \n",
    "    #model.train()\n",
    "\n",
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1cf85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
