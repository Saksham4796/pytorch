{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ce900f",
   "metadata": {},
   "source": [
    "### Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3717b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfb7f9",
   "metadata": {},
   "source": [
    "### Using CUDA if it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6821621",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440c836",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a0732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "sequence_length = 28\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec0c7c",
   "metadata": {},
   "source": [
    "### Creating a Recurrent Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad767f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Forward Propagation\n",
    "        out, _ = self.lstm(x, (h0,c0))\n",
    "        out = out.reshape(x.shape[0],-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675eaa74",
   "metadata": {},
   "source": [
    "### Checking the model on random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d877170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(28,256,2,10)\n",
    "x = torch.randn(64,28,28)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4ac9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2df001b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7642e-02,  3.5686e-03, -2.2869e-02, -3.3710e-03, -1.5651e-02,\n",
       "          3.7409e-02,  1.6406e-02, -1.0635e-02, -1.8747e-03, -1.6424e-02],\n",
       "        [ 8.2370e-03, -1.3177e-02, -1.7565e-02,  5.4534e-03, -6.3011e-03,\n",
       "          4.2388e-02,  1.3626e-02, -1.4901e-02, -4.6550e-03, -1.2420e-02],\n",
       "        [ 9.1973e-03, -6.0679e-03, -2.7110e-02,  3.8513e-03,  4.2878e-06,\n",
       "          4.6040e-02,  6.6781e-03, -2.5721e-02,  1.1702e-02, -1.7580e-03],\n",
       "        [ 2.9456e-03, -9.0138e-03, -2.1689e-02, -3.2404e-03, -9.6613e-03,\n",
       "          3.9641e-02,  6.9506e-03, -2.2616e-02, -4.3066e-03, -1.4642e-02],\n",
       "        [ 4.3008e-03, -6.0181e-03, -2.6823e-02,  7.3385e-03,  1.5283e-02,\n",
       "          2.6342e-02,  1.0997e-02, -1.0733e-02,  6.0544e-03, -5.9961e-03],\n",
       "        [ 4.1869e-03, -1.9029e-02, -1.6875e-02,  4.9076e-03, -1.7285e-02,\n",
       "          4.6964e-02,  1.1368e-02,  1.3215e-03,  1.0172e-03, -7.7779e-03],\n",
       "        [-2.5415e-03, -2.1129e-02, -2.6147e-02,  3.7797e-03,  1.0132e-03,\n",
       "          4.6278e-02,  2.1413e-02, -1.1361e-02, -1.0359e-03, -6.8277e-03],\n",
       "        [ 6.5441e-03, -2.6918e-03, -2.2810e-02, -5.9022e-03,  2.2619e-03,\n",
       "          3.0807e-02,  9.8403e-03, -1.0757e-02,  8.2324e-03, -5.9969e-03],\n",
       "        [-5.5679e-03, -3.7661e-03, -1.8991e-02,  5.1835e-03, -3.2210e-03,\n",
       "          3.7539e-02,  9.5261e-03, -1.6639e-02,  8.4240e-03,  1.0717e-02],\n",
       "        [ 1.7890e-02, -7.3025e-03, -1.6131e-02, -1.5238e-02, -3.4871e-04,\n",
       "          4.0713e-02,  5.4558e-03, -9.1936e-03,  3.6192e-03,  3.6798e-03],\n",
       "        [ 7.3784e-03, -8.7149e-03, -1.5040e-02, -1.6029e-03, -1.1722e-02,\n",
       "          3.9491e-02,  2.2512e-02, -1.3683e-02,  3.7433e-04, -9.6780e-03],\n",
       "        [ 8.0428e-03, -3.2872e-03, -1.5513e-02,  6.5523e-03, -1.5784e-02,\n",
       "          3.4208e-02,  1.2428e-02, -1.7011e-02, -9.2734e-04, -8.9344e-03],\n",
       "        [ 1.3146e-03, -1.4386e-02, -1.9519e-02, -1.5833e-02, -3.9418e-03,\n",
       "          4.2386e-02,  1.5650e-02, -7.4317e-03,  2.2088e-02, -9.7553e-03],\n",
       "        [-1.7047e-03, -1.6449e-02, -1.6575e-02,  7.1266e-04, -6.5967e-03,\n",
       "          4.4537e-02,  2.0278e-02, -1.4621e-02, -2.2912e-03, -3.5573e-03],\n",
       "        [ 1.1287e-02, -1.5476e-02, -3.3864e-02, -1.0011e-03, -1.0050e-02,\n",
       "          4.1056e-02,  2.2219e-02, -2.2841e-02,  1.6333e-02, -1.3738e-02],\n",
       "        [ 1.6276e-02, -1.4699e-02, -8.2589e-03,  7.7499e-04, -9.4860e-03,\n",
       "          3.5326e-02,  1.4926e-02, -1.7684e-02,  4.6591e-04, -7.5165e-04],\n",
       "        [ 8.0572e-03, -1.3282e-02, -9.9933e-03,  1.0819e-02, -1.4572e-02,\n",
       "          4.5965e-02,  3.5654e-03, -8.6463e-03, -2.4953e-05, -6.6384e-03],\n",
       "        [-4.1230e-03, -9.2018e-03, -2.2491e-02, -1.2526e-03, -5.1937e-03,\n",
       "          2.2843e-02,  1.4043e-02, -9.5041e-03,  4.0788e-03, -8.0655e-03],\n",
       "        [ 2.4513e-03, -1.0804e-02, -1.8083e-02,  8.5734e-04, -2.5248e-03,\n",
       "          4.1529e-02,  1.4261e-02, -2.0157e-02, -1.0313e-03, -1.2622e-02],\n",
       "        [ 8.4165e-03, -2.2422e-03, -2.3453e-02,  1.2685e-02, -1.1191e-02,\n",
       "          4.4653e-02,  2.8168e-02, -3.7492e-03, -7.9719e-03, -1.7336e-02],\n",
       "        [ 1.3383e-02, -6.8495e-03, -2.5025e-02,  2.6325e-03, -7.4872e-03,\n",
       "          3.8716e-02,  2.2043e-02, -1.0154e-02,  1.7720e-04, -2.6103e-02],\n",
       "        [ 1.9192e-02, -1.9090e-02, -1.5591e-02,  7.0765e-03, -4.5438e-03,\n",
       "          4.0513e-02,  1.1769e-02, -1.6026e-02,  3.9982e-03, -1.6109e-02],\n",
       "        [ 6.3571e-03, -2.2892e-03, -1.4979e-02, -9.1471e-03, -6.2601e-03,\n",
       "          4.0016e-02,  1.5146e-02, -1.2694e-02, -3.5872e-03,  2.0504e-03],\n",
       "        [-3.0525e-05, -2.4767e-02, -1.6718e-02,  5.0942e-03, -5.9032e-03,\n",
       "          4.4180e-02,  5.5041e-03, -1.4863e-02, -1.3808e-03, -3.1454e-03],\n",
       "        [ 1.5399e-02, -7.3929e-03, -1.7887e-02,  3.0707e-03, -7.1437e-03,\n",
       "          2.3787e-02,  1.3742e-03, -5.3411e-03,  1.6305e-02, -5.5296e-03],\n",
       "        [ 4.2404e-03, -2.1540e-03, -2.1307e-02,  2.0384e-03,  7.1778e-04,\n",
       "          3.1305e-02,  1.9953e-03, -2.3219e-02,  1.2890e-02, -4.2684e-03],\n",
       "        [ 2.0810e-02,  6.9820e-03, -2.9504e-02,  1.4277e-03, -1.7271e-02,\n",
       "          3.4946e-02,  1.6918e-02, -1.8075e-02,  4.0111e-03, -1.0879e-02],\n",
       "        [ 1.3433e-03, -1.8823e-02, -2.0481e-02, -5.5850e-03, -1.3741e-02,\n",
       "          3.5454e-02,  2.5103e-02, -1.2549e-03, -4.0288e-03, -9.7346e-03],\n",
       "        [ 6.0432e-03, -1.0372e-02, -2.1511e-02, -9.2380e-03, -1.7390e-02,\n",
       "          3.8498e-02,  4.7349e-03, -8.8680e-03,  1.2774e-02, -2.2183e-02],\n",
       "        [ 1.7399e-03, -2.1278e-02, -2.3137e-02,  2.4701e-03, -1.1180e-02,\n",
       "          3.6476e-02,  1.4021e-02, -6.1006e-03,  6.2445e-03, -7.7358e-03],\n",
       "        [ 1.1266e-02, -1.4581e-02, -2.6707e-02, -2.5828e-03, -1.3665e-02,\n",
       "          5.5193e-02,  1.9408e-02, -2.4184e-02,  5.9947e-03, -2.3053e-02],\n",
       "        [ 8.0884e-03, -5.2951e-03, -3.0727e-02,  1.1512e-03, -5.1008e-03,\n",
       "          4.2597e-02,  1.4756e-02, -9.8651e-03, -8.8917e-04, -1.3806e-02],\n",
       "        [ 1.7350e-02,  1.1976e-03, -1.1027e-02, -6.4262e-03, -7.3724e-03,\n",
       "          3.6196e-02, -6.4998e-04, -1.1094e-02,  5.9167e-03, -8.1804e-03],\n",
       "        [ 1.0429e-02, -1.0328e-02, -1.9636e-02,  2.4145e-03,  3.2373e-03,\n",
       "          3.7482e-02,  2.1115e-02, -1.4141e-02,  1.3171e-02, -8.2269e-03],\n",
       "        [ 9.1116e-03, -6.5850e-03, -2.2696e-02, -1.0068e-03, -1.2512e-02,\n",
       "          2.8943e-02,  1.5969e-02, -8.4518e-03,  7.7325e-03, -8.3756e-03],\n",
       "        [ 5.3807e-03, -1.7868e-02, -2.6329e-02, -1.1313e-02,  2.7407e-03,\n",
       "          5.1768e-02,  1.1022e-02, -9.5617e-03,  1.3262e-02, -6.3660e-03],\n",
       "        [-4.2534e-03, -1.0119e-02, -2.2415e-02, -1.1320e-02, -1.5101e-03,\n",
       "          3.9220e-02,  2.0992e-02, -2.7200e-02,  4.2520e-03, -5.5794e-03],\n",
       "        [ 1.3519e-02, -2.3721e-02, -3.0258e-02, -1.3294e-03, -5.9036e-03,\n",
       "          4.2496e-02,  1.6620e-02, -4.9433e-03, -2.7106e-03, -5.1138e-03],\n",
       "        [ 1.7540e-03,  5.2287e-03, -2.1337e-02, -3.9771e-03, -7.4166e-03,\n",
       "          3.9199e-02,  1.1212e-02, -1.3540e-02,  1.4913e-02, -3.1024e-03],\n",
       "        [ 7.9537e-03, -1.9174e-02, -1.6873e-02,  7.7461e-03, -1.4553e-03,\n",
       "          3.2304e-02,  8.9350e-03,  8.4494e-05,  1.5009e-03, -8.5533e-03],\n",
       "        [ 4.2485e-03, -3.3430e-03, -1.1553e-02,  2.7522e-03, -9.3203e-03,\n",
       "          3.9051e-02,  2.4625e-02,  4.3761e-03,  6.9147e-03, -1.1774e-02],\n",
       "        [ 5.7289e-03, -5.9219e-03, -1.2078e-02,  6.2660e-04,  5.1972e-03,\n",
       "          3.1125e-02,  5.6482e-03,  6.8017e-03,  3.7750e-03, -4.0257e-03],\n",
       "        [ 1.0967e-02, -8.8348e-03, -5.2655e-04, -4.0320e-03, -6.6603e-03,\n",
       "          3.5005e-02,  1.3994e-02, -6.3369e-03,  1.3528e-02, -1.9386e-02],\n",
       "        [ 1.1348e-02, -1.7083e-02, -2.2197e-02, -1.9188e-03, -8.4804e-03,\n",
       "          4.6023e-02,  1.1667e-02, -1.9957e-03, -2.3840e-03, -8.6702e-03],\n",
       "        [-3.3224e-03, -3.6376e-03, -2.2238e-02, -1.8100e-04,  3.5165e-03,\n",
       "          3.8346e-02,  1.9892e-02, -2.6898e-02,  7.4922e-03, -1.7296e-02],\n",
       "        [ 6.2607e-03, -1.3641e-02, -2.3595e-02, -1.9302e-03, -1.1329e-02,\n",
       "          4.2450e-02,  1.3835e-02, -2.0989e-02,  8.8706e-03, -2.4369e-02],\n",
       "        [ 1.8411e-02, -1.3526e-03, -3.1422e-02, -3.5420e-03, -2.6496e-03,\n",
       "          5.0333e-02,  1.1455e-02, -2.5751e-02,  8.8042e-03, -8.6083e-03],\n",
       "        [-2.3830e-03, -3.2789e-03, -2.0737e-02, -1.7902e-03, -7.0670e-03,\n",
       "          3.0975e-02,  1.1993e-02, -1.9868e-02, -2.7589e-03, -6.9093e-05],\n",
       "        [ 1.0322e-02, -8.3002e-03, -1.5939e-02, -1.1766e-02, -1.0619e-02,\n",
       "          4.1877e-02,  1.5328e-02, -1.9881e-02,  1.5413e-02, -4.7070e-03],\n",
       "        [ 7.6965e-03, -1.9865e-02, -1.4242e-02,  8.0525e-03, -2.0839e-02,\n",
       "          3.9005e-02,  2.8425e-02, -7.2848e-03, -2.4517e-03, -9.9298e-03],\n",
       "        [ 3.4740e-03, -1.7023e-02, -2.6670e-02, -7.1993e-03, -1.5497e-02,\n",
       "          4.1421e-02,  7.2313e-03, -1.8087e-02,  5.4249e-03, -3.2835e-02],\n",
       "        [ 1.4203e-02, -1.5336e-02, -3.5339e-02, -4.5308e-03, -8.4000e-03,\n",
       "          4.8963e-02,  1.4166e-02, -2.2334e-02,  2.6233e-03, -2.0717e-02],\n",
       "        [ 1.6476e-02, -1.1389e-02, -2.7877e-02,  3.8238e-03, -2.8692e-04,\n",
       "          4.0683e-02,  8.4702e-03, -3.2790e-03,  9.7203e-05, -8.4420e-03],\n",
       "        [ 1.2246e-02, -1.3621e-02, -3.2083e-02,  5.0293e-03, -4.5329e-03,\n",
       "          4.2362e-02,  1.1149e-02, -1.0801e-02, -6.5027e-03, -7.9084e-03],\n",
       "        [ 5.6265e-04, -4.6289e-03, -2.1962e-02,  1.2158e-02,  1.9131e-03,\n",
       "          4.0576e-02,  6.4520e-03, -1.2231e-02, -1.3348e-03, -1.4541e-02],\n",
       "        [ 1.0843e-03,  3.2520e-03, -1.3270e-02,  1.2604e-03, -6.3784e-04,\n",
       "          4.5656e-02,  3.9649e-03, -1.8253e-02, -1.0337e-02, -1.3546e-02],\n",
       "        [-6.1328e-03, -6.3347e-03, -1.2707e-02,  1.2036e-02,  9.4555e-03,\n",
       "          3.8322e-02,  1.3053e-02,  3.5480e-03,  1.8044e-03, -1.5071e-02],\n",
       "        [-1.0154e-02, -5.6523e-03, -3.2259e-03, -8.6035e-04,  2.2480e-03,\n",
       "          4.2357e-02,  5.7107e-03, -1.9520e-02, -3.0244e-03,  9.5379e-03],\n",
       "        [ 1.5477e-02, -1.7218e-02, -1.9771e-02, -1.1970e-02, -3.8713e-03,\n",
       "          3.6594e-02,  1.1686e-02, -1.6227e-02, -3.9687e-03, -2.6841e-03],\n",
       "        [ 4.3090e-03,  5.6876e-03, -6.1143e-03,  7.3067e-03,  4.7574e-03,\n",
       "          3.9905e-02,  1.1268e-02, -1.0611e-02, -8.0982e-03, -1.7276e-02],\n",
       "        [-5.6651e-03, -9.9768e-03, -2.0440e-02,  6.4001e-03,  5.4353e-03,\n",
       "          4.3995e-02,  8.4648e-03, -2.5909e-02,  7.8933e-03,  1.5044e-04],\n",
       "        [ 3.0496e-03, -2.6425e-03, -2.3112e-02, -3.7743e-03, -1.3232e-02,\n",
       "          4.6513e-02,  1.9933e-02, -1.2380e-02,  8.6654e-03, -1.1715e-02],\n",
       "        [ 1.4464e-02, -1.5673e-02, -1.6662e-02, -4.6651e-03, -2.4368e-02,\n",
       "          5.4378e-02,  1.3837e-02, -3.2082e-04,  1.4962e-02, -2.5546e-02],\n",
       "        [ 5.7083e-03, -1.1812e-02, -1.3435e-02, -6.0508e-03, -6.1144e-03,\n",
       "          4.1732e-02,  1.7264e-02, -1.4943e-02,  7.8572e-03, -1.5511e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f0d97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0042,  0.0007,  0.0168, -0.0356,  0.0207,  0.0088,  0.0034,  0.0095,\n",
       "         0.0232,  0.0231,  0.0093, -0.0002,  0.0106,  0.0037, -0.0061,  0.0169,\n",
       "         0.0152, -0.0189, -0.0061,  0.0280,  0.0013,  0.0112,  0.0146, -0.0120,\n",
       "         0.0166,  0.0022,  0.0094, -0.0117, -0.0275, -0.0085, -0.0129,  0.0009,\n",
       "         0.0159,  0.0355,  0.0021,  0.0127, -0.0179, -0.0013,  0.0229,  0.0125,\n",
       "         0.0460,  0.0369,  0.0277,  0.0063, -0.0043, -0.0244,  0.0157, -0.0150,\n",
       "         0.0117,  0.0086, -0.0598, -0.0267,  0.0183, -0.0047,  0.0070, -0.0008,\n",
       "         0.0380,  0.0174, -0.0120,  0.0311,  0.0103,  0.0113,  0.0104,  0.0047],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->i\",arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6fef5",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf5dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='data/',train=True, transform=transforms.ToTensor(),download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='data/',train=False, transform=transforms.ToTensor(),download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131db9d9",
   "metadata": {},
   "source": [
    "### Intialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b39a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size,hidden_size,num_layers,num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d57d3",
   "metadata": {},
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f91635",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d12ef",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc77c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get the data to CUDA if possible\n",
    "        data = data.to(device=device).squeeze(1)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,targets)\n",
    "        \n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Descent\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df6464",
   "metadata": {},
   "source": [
    "### Checking the accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b07e065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 57563/60000 with accuracy 95.94\n",
      "Checking accuracy on test data\n",
      "Got 9612/10000 with accuracy 96.12\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "        \n",
    "    else :\n",
    "        print(\"Checking accuracy on test data\")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    #model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device).squeeze(1)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            \n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "    print(f'Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "        \n",
    "    #model.train()\n",
    "\n",
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1cf85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
